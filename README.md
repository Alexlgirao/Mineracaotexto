## Mineração texto
A premissa desse trabalho criar um crawler para procurar em um ou vários sites de notícias, no caso o G1, por entradas sobre um assunto. No caso do código sobre afogamentos. 

# Roadmap

# Parte 1 

Criar um crawler para pesquisar notícias sobre o assunto relacionado

Extrair um número x dos links mais recentes

Tratar os links para remover vídeos e propagandas

Extrair os textos dos artigos

Tratar o texto, remover palavras de ligação, números, pontuação

Contar as palavras 

Criar uma nuvem de palavras 

Fazer uma análise sobre o resultado

# Parte 2 

Visualizar as correlações no Gephi

Gerar as entidades 

Tratar as duplicidades

Gerar o arquivo para o Graphi

# Parte 3

No Graphi tratar as inconsistências, limpeza e manipulação das entidades

Criar a visualização

Analisar a visualização

# Parte 4

Análise final do resultado


# to do
Transformar o codigo em markdown com a análise feita 

Fiz a pesquisa sobre Afogamentos. E ao analisar os dados do G1 , no wordcloud , ficou evidente que sábado, domingo e homem eram os dias de mais ocorrências e quem mais morria, até ai tudo bem. A surpresa veio quando nas entidades eu separei por localidade , pois queria ter uma noção de volume de mortes por localidade e posteriormente bater com os dados oficiais e se poderia ser correlacionado de alguma forma. A surpresa veio como a ausência de matérias com localidade rio de janeiro, aumentei o numero de paginas de pesquisa e nada havia mudado. Fui atrás dos dados oficiais e realmente o numero de óbitos por afogamento no RJ é absurdamente inferior a media dos outros estados. Chegando quase a 0. A conclusão que eu tive que a falta de dados é um dado relevante! E que a quantidade de matérias sobre mortes por afogamento é compatível( falta criar um modelo descritivo) com o numero real de casos. 
